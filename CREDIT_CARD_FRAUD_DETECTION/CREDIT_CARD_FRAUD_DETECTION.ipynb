{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Title: Credit Card Fraud Detection\n",
    "#### Done By: Nozipho Sithembiso Ndebele\n",
    "---\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"https://www.practicalecommerce.com/wp-content/uploads/2019/02/Credit-card-fraud.jpg\"alt=\"credit Image\" width=\"1000\"/>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#BC> Background Context</a>\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Data Collection and Description</a>\n",
    "\n",
    "<a href=#three>3. Loading Data </a>\n",
    "\n",
    "<a href=#four>4. Data Cleaning and Filtering</a>\n",
    "\n",
    "<a href=#five>5. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#six>6. Modeling </a>\n",
    "\n",
    "<a href=#seven>7. Evaluation and Validation</a>\n",
    "\n",
    "<a href=#eight>8. Final Model</a>\n",
    "\n",
    "<a href=#nine>9. Conclusion and Future Work</a>\n",
    "\n",
    "<a href=#ten>10. References</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    " <a id=\"BC\"></a>\n",
    "## **Background Context**\n",
    "\n",
    "### Purpose\n",
    "\n",
    "\n",
    "### Significance\n",
    "\n",
    "### Problem Domain\n",
    "\n",
    "### Challenges\n",
    "\n",
    "\n",
    "### Key Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#one></a>\n",
    "## **Importing Packages**\n",
    "\n",
    "### Purpose\n",
    "To set up the Python environment with the necessary libraries for data manipulation, visualization, and machine learning. These libraries will facilitate data preprocessing, feature extraction, model training, and evaluation.\n",
    "\n",
    "### Details\n",
    "* Pandas: For handling and analyzing data.\n",
    "\n",
    "* NumPy: For numerical operations.\n",
    "\n",
    "* Matplotlib/Seaborn: For data visualization to understand trends and patterns.\n",
    "\n",
    "* scikit-learn: For building and evaluating machine learning models.\n",
    "\n",
    "* NLTK/Spacy: For text preprocessing and natural language processing tasks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages  \n",
    "\n",
    "# Data manipulation and analysis  \n",
    "import pandas as pd  # Pandas for data handling  \n",
    "import numpy as np  # NumPy for numerical operations  \n",
    "\n",
    "# Data visualization  \n",
    "import matplotlib.pyplot as plt  # Matplotlib for static plots  \n",
    "import seaborn as sns  # Seaborn for statistical visualization  \n",
    "import plotly.express as px  # Plotly for interactive plots  \n",
    "\n",
    "# Natural Language Processing  \n",
    "import nltk  # Natural Language Toolkit  \n",
    "from nltk.corpus import stopwords  # Stopword removal  \n",
    "from nltk.tokenize import word_tokenize  # Tokenization  \n",
    "import re  # Regular expressions for text cleaning  \n",
    "\n",
    "# Configure visualization settings\n",
    "sns.set(style='whitegrid')  # Set the default style for Seaborn plots\n",
    "plt.rcParams['figure.figsize'] = (10, 6)  # Set default figure size for Matplotlib\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings  # Import the warnings module\n",
    "warnings.filterwarnings('ignore')  # Ignore all warning messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#two></a>\n",
    "## **Data Collection and Description**\n",
    "### Purpose\n",
    "\n",
    "\n",
    "### Details\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#three></a>\n",
    "## **Loading Data**\n",
    "### Purpose\n",
    "The purpose of this section is to load the dataset into the notebook for further manipulation and analysis. This is the first step in working with the data, and it allows us to inspect the raw data and get a sense of its structure.\n",
    "\n",
    "### Details\n",
    "In this section, we will load the dataset into a Pandas DataFrame and display the first few rows to understand what the raw data looks like. This will help in planning the next steps of data cleaning and analysis.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into a Pandas DataFrame\n",
    "\n",
    "# The dataset is stored in a CSV file named 'Domestic violence.csv'\n",
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df is the original dataset (DataFrame), this creates a copy of it\n",
    "df_copy = df.copy()\n",
    "\n",
    "# Now 'df_copy' is an independent copy of 'df'. Changes to 'df_copy' won't affect 'df'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the dataset to get a sense of what the raw data looks like\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the number of rows and columns in the dataset to understand its size\n",
    "df_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Check the structure of the dataset\n",
    "df_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#four></a>\n",
    "## **Data Cleaning and Filtering**\n",
    "Before analyzing the data, it is crucial to clean and filter it. This process involves handling missing values, removing outliers, correcting errors, and possibly reducing the data by filtering out irrelevant features. These steps ensure that the analysis is based on accurate and reliable data.\n",
    "\n",
    "Details\n",
    "In this section, we will:\n",
    "\n",
    "* Check for Missing Values: Identify if there are any missing values in the dataset and handle them accordingly.\n",
    "* Remove Duplicates: Ensure there are no duplicate rows that could skew the analysis.\n",
    "* Correct Errors: Look for and correct any obvious data entry errors.\n",
    "* Filter Data: Depending on the analysis requirements, filter the data to include only relevant records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Check for missing values in the dataset\n",
    "\n",
    "def check_missing_values(df):\n",
    "    \"\"\"\n",
    "    Check for missing values in the dataset and display the number of missing values per column.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The dataset to check for missing values.\n",
    "\n",
    "    Returns:\n",
    "    pandas.Series: A series showing the number of missing values for each column.\n",
    "    \"\"\"\n",
    "     # Check for missing values in the dataset and display them\n",
    "    print(\"Missing values per column:\")\n",
    "    missing_values = df.isnull().sum()\n",
    "    print(missing_values)\n",
    "    return missing_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame\n",
    "missing_values = check_missing_values(df_copy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After examining the dataset, no missing values were found across any of the columns. This ensures data completeness and eliminates the need for imputation or further cleaning related to missing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df):\n",
    "    \"\"\"\n",
    "    Checks for duplicate rows in the dataset and removes them if any are found.\n",
    "\n",
    "    Args:\n",
    "    df (pandas.DataFrame): The dataframe to check for duplicate rows.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The dataframe with duplicate rows removed, if any existed.\n",
    "    \"\"\"\n",
    "    # Check for duplicate rows\n",
    "    duplicate_rows = df.duplicated().sum()\n",
    "    print(f\"\\nNumber of duplicate rows: {duplicate_rows}\")\n",
    "    \n",
    "    # Remove duplicates if any exist\n",
    "    if duplicate_rows > 0:\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        print(f\"Duplicate rows removed. Updated dataframe has {len(df)} rows.\")\n",
    "    else:\n",
    "        print(\"No duplicate rows found.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of duplicate rows: 1081\n",
      "Duplicate rows removed. Updated dataframe has 283726 rows.\n"
     ]
    }
   ],
   "source": [
    "df_copy = remove_duplicates(df_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon reviewing the dataset, 1081 duplicate rows were found and removed. This ensures that all records are unique, and no further action is required for data deduplication.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Saving the Cleaned Dataset**\n",
    "### Purpose\n",
    "\n",
    "This section outlines how to save the cleaned dataset for future use. Saving the dataset ensures that the data cleaning process does not need to be repeated and allows for consistent use in subsequent analyses.\n",
    "\n",
    "### Details\n",
    "\n",
    "We will save the cleaned dataset as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Save the cleaned dataset to a new CSV file\n",
    "\n",
    "def save_cleaned_dataset(df, filename='cleaned_creditcard.csv'):\n",
    "    \"\"\"\n",
    "    Saves the cleaned dataframe to a CSV file.\n",
    "\n",
    "    Args:\n",
    "    df (pandas.DataFrame): The cleaned dataframe to save.\n",
    "    filename (str): The name of the file to save the dataframe to (default is 'cleaned_domestic_violence.csv').\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Save the cleaned dataset to a CSV file\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Cleaned dataset saved successfully as '{filename}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved successfully as 'cleaned_creditcard.csv'.\n"
     ]
    }
   ],
   "source": [
    "save_cleaned_dataset(df_copy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#five></a>\n",
    "## **Exploratory Data Analysis (EDA)**\n",
    "\n",
    "It is the process of analyzing datasets to summarize key features, often through visualization methods. It aims to discover patterns, spot anomalies, and formulate hypotheses for deeper insights, which informs subsequent analysis.\n",
    "#### Advantages\n",
    "\n",
    "- Helps in understanding the data before modeling.\n",
    "- Provides insights that guide feature selection and engineering.\n",
    "- Assists in choosing appropriate modeling techniques.\n",
    "- Uncovers potential data quality issues early.\n",
    "\n",
    "`The following methods were employed to communicate our objective:`\n",
    "\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#nine></a>\n",
    "## **Conclusion and Future Work**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion\n",
    "\n",
    "\n",
    "\n",
    "##### Future Work\n",
    "\n",
    "To build upon this study, future work could focus on the following areas:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#ten></a>\n",
    "## **References**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Sections to Consider\n",
    "\n",
    "**Contributors**: Nozipho Sithembiso Ndebele\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
