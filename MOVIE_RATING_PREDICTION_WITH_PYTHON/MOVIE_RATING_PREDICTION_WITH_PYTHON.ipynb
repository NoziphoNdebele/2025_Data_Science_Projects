{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Title: Movie Rating Prediction With Python\n",
    "#### Done By: Nozipho Sithembiso Ndebele\n",
    "---\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"https://nycdsa-blog-files.s3.us-east-2.amazonaws.com/2016/08/Screen-Shot-2016-08-21-at-3.20.01-PM.png\" alt=\"Movie Image\" width=\"1000\"/>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#BC> Background Context</a>\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Data Collection and Description</a>\n",
    "\n",
    "<a href=#three>3. Loading Data </a>\n",
    "\n",
    "<a href=#four>4. Data Cleaning and Filtering</a>\n",
    "\n",
    "<a href=#five>5. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#six>6. Modeling </a>\n",
    "\n",
    "<a href=#seven>7. Evaluation and Validation</a>\n",
    "\n",
    "<a href=#eight>8. Final Model</a>\n",
    "\n",
    "<a href=#nine>9. Conclusion and Future Work</a>\n",
    "\n",
    "<a href=#ten>10. References</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    " <a id=\"BC\"></a>\n",
    "## **Background Context**\n",
    "\n",
    "### Purpose\n",
    "\n",
    "### Significance\n",
    "\n",
    "\n",
    "### Problem Domain\n",
    "\n",
    "### Challenges\n",
    "\n",
    "\n",
    "### Key Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#one></a>\n",
    "## **Importing Packages**\n",
    "\n",
    "### Purpose\n",
    "To set up the Python environment with the necessary libraries for data manipulation, visualization, and machine learning. These libraries will facilitate data preprocessing, feature extraction, model training, and evaluation.\n",
    "\n",
    "### Details\n",
    "* Pandas: For handling and analyzing data.\n",
    "\n",
    "* NumPy: For numerical operations.\n",
    "\n",
    "* Matplotlib/Seaborn: For data visualization to understand trends and patterns.\n",
    "\n",
    "* scikit-learn: For building and evaluating machine learning models.\n",
    "\n",
    "* NLTK/Spacy: For text preprocessing and natural language processing tasks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages  \n",
    "\n",
    "# Data manipulation and analysis  \n",
    "import pandas as pd  # Pandas for data handling  \n",
    "import numpy as np  # NumPy for numerical operations  \n",
    "\n",
    "# Data visualization  \n",
    "import matplotlib.pyplot as plt  # Matplotlib for static plots  \n",
    "import seaborn as sns  # Seaborn for statistical visualization  \n",
    "import plotly.express as px  # Plotly for interactive plots  \n",
    "\n",
    "# Natural Language Processing  \n",
    "import nltk  # Natural Language Toolkit  \n",
    "from nltk.corpus import stopwords  # Stopword removal  \n",
    "from nltk.tokenize import word_tokenize  # Tokenization  \n",
    "import re  # Regular expressions for text cleaning  \n",
    "\n",
    "# Configure visualization settings\n",
    "sns.set(style='whitegrid')  # Set the default style for Seaborn plots\n",
    "plt.rcParams['figure.figsize'] = (10, 6)  # Set default figure size for Matplotlib\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings  # Import the warnings module\n",
    "warnings.filterwarnings('ignore')  # Ignore all warning messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#two></a>\n",
    "## **Data Collection and Description**\n",
    "### Purpose\n",
    "\n",
    "### Details\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#three></a>\n",
    "## **Loading Data**\n",
    "### Purpose\n",
    "The purpose of this section is to load the dataset into the notebook for further manipulation and analysis. This is the first step in working with the data, and it allows us to inspect the raw data and get a sense of its structure.\n",
    "\n",
    "### Details\n",
    "In this section, we will load the dataset into a Pandas DataFrame and display the first few rows to understand what the raw data looks like. This will help in planning the next steps of data cleaning and analysis.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into a Pandas DataFrame\n",
    "\n",
    "# The dataset is stored in a CSV file named 'IMDb Movies India.csv'\n",
    "df = pd.read_csv('IMDb Movies India.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df is the original dataset (DataFrame), this creates a copy of it\n",
    "df_copy = df.copy()\n",
    "\n",
    "# Now 'df_copy' is an independent copy of 'df'. Changes to 'df_copy' won't affect 'df'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "      <th>Director</th>\n",
       "      <th>Actor 1</th>\n",
       "      <th>Actor 2</th>\n",
       "      <th>Actor 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J.S. Randhawa</td>\n",
       "      <td>Manmauji</td>\n",
       "      <td>Birbal</td>\n",
       "      <td>Rajendra Bhatia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#Gadhvi (He thought he was Gandhi)</td>\n",
       "      <td>(2019)</td>\n",
       "      <td>109 min</td>\n",
       "      <td>Drama</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>Gaurav Bakshi</td>\n",
       "      <td>Rasika Dugal</td>\n",
       "      <td>Vivek Ghamande</td>\n",
       "      <td>Arvind Jangid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Homecoming</td>\n",
       "      <td>(2021)</td>\n",
       "      <td>90 min</td>\n",
       "      <td>Drama, Musical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Soumyajit Majumdar</td>\n",
       "      <td>Sayani Gupta</td>\n",
       "      <td>Plabita Borthakur</td>\n",
       "      <td>Roy Angana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Yaaram</td>\n",
       "      <td>(2019)</td>\n",
       "      <td>110 min</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>4.4</td>\n",
       "      <td>35</td>\n",
       "      <td>Ovais Khan</td>\n",
       "      <td>Prateik</td>\n",
       "      <td>Ishita Raj</td>\n",
       "      <td>Siddhant Kapoor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>...And Once Again</td>\n",
       "      <td>(2010)</td>\n",
       "      <td>105 min</td>\n",
       "      <td>Drama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amol Palekar</td>\n",
       "      <td>Rajat Kapoor</td>\n",
       "      <td>Rituparna Sengupta</td>\n",
       "      <td>Antara Mali</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Name    Year Duration            Genre  \\\n",
       "0                                         NaN      NaN            Drama   \n",
       "1  #Gadhvi (He thought he was Gandhi)  (2019)  109 min            Drama   \n",
       "2                         #Homecoming  (2021)   90 min   Drama, Musical   \n",
       "3                             #Yaaram  (2019)  110 min  Comedy, Romance   \n",
       "4                   ...And Once Again  (2010)  105 min            Drama   \n",
       "\n",
       "   Rating Votes            Director       Actor 1             Actor 2  \\\n",
       "0     NaN   NaN       J.S. Randhawa      Manmauji              Birbal   \n",
       "1     7.0     8       Gaurav Bakshi  Rasika Dugal      Vivek Ghamande   \n",
       "2     NaN   NaN  Soumyajit Majumdar  Sayani Gupta   Plabita Borthakur   \n",
       "3     4.4    35          Ovais Khan       Prateik          Ishita Raj   \n",
       "4     NaN   NaN        Amol Palekar  Rajat Kapoor  Rituparna Sengupta   \n",
       "\n",
       "           Actor 3  \n",
       "0  Rajendra Bhatia  \n",
       "1    Arvind Jangid  \n",
       "2       Roy Angana  \n",
       "3  Siddhant Kapoor  \n",
       "4      Antara Mali  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the dataset to get a sense of what the raw data looks like\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15509, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the number of rows and columns in the dataset to understand its size\n",
    "df_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15509 entries, 0 to 15508\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Name      15509 non-null  object \n",
      " 1   Year      14981 non-null  object \n",
      " 2   Duration  7240 non-null   object \n",
      " 3   Genre     13632 non-null  object \n",
      " 4   Rating    7919 non-null   float64\n",
      " 5   Votes     7920 non-null   object \n",
      " 6   Director  14984 non-null  object \n",
      " 7   Actor 1   13892 non-null  object \n",
      " 8   Actor 2   13125 non-null  object \n",
      " 9   Actor 3   12365 non-null  object \n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check the structure of the dataset\n",
    "df_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#four></a>\n",
    "## **Data Cleaning and Filtering**\n",
    "Before analyzing the data, it is crucial to clean and filter it. This process involves handling missing values, removing outliers, correcting errors, and possibly reducing the data by filtering out irrelevant features. These steps ensure that the analysis is based on accurate and reliable data.\n",
    "\n",
    "Details\n",
    "In this section, we will:\n",
    "\n",
    "* Check for Missing Values: Identify if there are any missing values in the dataset and handle them accordingly.\n",
    "* Remove Duplicates: Ensure there are no duplicate rows that could skew the analysis.\n",
    "* Correct Errors: Look for and correct any obvious data entry errors.\n",
    "* Filter Data: Depending on the analysis requirements, filter the data to include only relevant records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Check for missing values in the dataset\n",
    "\n",
    "def check_missing_values(df):\n",
    "    \"\"\"\n",
    "    Check for missing values in the dataset and display the number of missing values per column.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The dataset to check for missing values.\n",
    "\n",
    "    Returns:\n",
    "    pandas.Series: A series showing the number of missing values for each column.\n",
    "    \"\"\"\n",
    "     # Check for missing values in the dataset and display them\n",
    "    print(\"Missing values per column:\")\n",
    "    missing_values = df.isnull().sum()\n",
    "    print(missing_values)\n",
    "    return missing_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "Name           0\n",
      "Year         528\n",
      "Duration    8269\n",
      "Genre       1877\n",
      "Rating      7590\n",
      "Votes       7589\n",
      "Director     525\n",
      "Actor 1     1617\n",
      "Actor 2     2384\n",
      "Actor 3     3144\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame\n",
    "missing_values = check_missing_values(df_copy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After examining the dataset, missing values were identified in some  columns. All other columns are complete, ensuring data integrity for most features. Depending on the analysis goals, handling these missing values may be necessary through imputation or other data-cleaning techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing_values(df):\n",
    "    \"\"\"\n",
    "    Drops rows with missing values in specified important columns.\n",
    "\n",
    "    Args:\n",
    "    df (pandas.DataFrame): The dataframe to process.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The dataframe with rows containing missing values dropped.\n",
    "    \"\"\"\n",
    "    # Columns to check for missing values\n",
    "    columns_to_check = ['Year', 'Duration', 'Genre', 'Rating', 'Votes', \n",
    "                        'Director', 'Actor 1', 'Actor 2', 'Actor 3']\n",
    "\n",
    "    # Count missing values before\n",
    "    missing_before = df[columns_to_check].isnull().sum().sum()\n",
    "    print(f\"\\nMissing values before dropping: {missing_before}\")\n",
    "\n",
    "    # Drop rows with any missing values in the specified columns\n",
    "    df = df.dropna(subset=columns_to_check)\n",
    "\n",
    "    # Count missing values after\n",
    "    missing_after = df[columns_to_check].isnull().sum().sum()\n",
    "    print(f\"Missing values after dropping: {missing_after}\")\n",
    "    print(f\"Remaining rows: {df.shape[0]}\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values before dropping: 33523\n",
      "Missing values after dropping: 0\n",
      "Remaining rows: 5659\n"
     ]
    }
   ],
   "source": [
    "# Call the function\n",
    "df_copy = drop_missing_values(df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df):\n",
    "    \"\"\"\n",
    "    Checks for duplicate rows in the dataset and removes them if any are found.\n",
    "\n",
    "    Args:\n",
    "    df (pandas.DataFrame): The dataframe to check for duplicate rows.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The dataframe with duplicate rows removed, if any existed.\n",
    "    \"\"\"\n",
    "    # Check for duplicate rows\n",
    "    duplicate_rows = df.duplicated().sum()\n",
    "    print(f\"\\nNumber of duplicate rows: {duplicate_rows}\")\n",
    "    \n",
    "    # Remove duplicates if any exist\n",
    "    if duplicate_rows > 0:\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        print(f\"Duplicate rows removed. Updated dataframe has {len(df)} rows.\")\n",
    "    else:\n",
    "        print(\"No duplicate rows found.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of duplicate rows: 0\n",
      "No duplicate rows found.\n"
     ]
    }
   ],
   "source": [
    "df_copy = remove_duplicates(df_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon reviewing the dataset, no duplicate rows were found. This ensures that all records are unique, and no further action is required for data deduplication.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Saving the Cleaned Dataset**\n",
    "### Purpose\n",
    "\n",
    "This section outlines how to save the cleaned dataset for future use. Saving the dataset ensures that the data cleaning process does not need to be repeated and allows for consistent use in subsequent analyses.\n",
    "\n",
    "### Details\n",
    "\n",
    "We will save the cleaned dataset as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Save the cleaned dataset to a new CSV file\n",
    "\n",
    "def save_cleaned_dataset(df, filename='cleaned_IMDb_Movies_India.csv'):\n",
    "    \"\"\"\n",
    "    Saves the cleaned dataframe to a CSV file.\n",
    "\n",
    "    Args:\n",
    "    df (pandas.DataFrame): The cleaned dataframe to save.\n",
    "    filename (str): The name of the file to save the dataframe to (default is 'cleaned_domestic_violence.csv').\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Save the cleaned dataset to a CSV file\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Cleaned dataset saved successfully as '{filename}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved successfully as 'cleaned_IMDb_Movies_India.csv'.\n"
     ]
    }
   ],
   "source": [
    "save_cleaned_dataset(df_copy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#five></a>\n",
    "## **Exploratory Data Analysis (EDA)**\n",
    "\n",
    "It is the process of analyzing datasets to summarize key features, often through visualization methods. It aims to discover patterns, spot anomalies, and formulate hypotheses for deeper insights, which informs subsequent analysis.\n",
    "#### Advantages\n",
    "\n",
    "- Helps in understanding the data before modeling.\n",
    "- Provides insights that guide feature selection and engineering.\n",
    "- Assists in choosing appropriate modeling techniques.\n",
    "- Uncovers potential data quality issues early.\n",
    "\n",
    "`The following methods were employed to communicate our objective:`\n",
    "\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#nine></a>\n",
    "## **Conclusion and Future Work**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion\n",
    "\n",
    "\n",
    "\n",
    "##### Future Work\n",
    "\n",
    "To build upon this study, future work could focus on the following areas:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href=#ten></a>\n",
    "## **References**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Sections to Consider\n",
    "\n",
    "**Contributors**: Nozipho Sithembiso Ndebele\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
